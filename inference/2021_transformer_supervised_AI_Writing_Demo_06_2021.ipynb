{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hululuzhu/chinese-ai-writing-share/blob/main/inference/2021_transformer_supervised_AI_Writing_Demo_06_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipB2xHkn-asg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Connect to Google Drive to reference [models and vocabs](https://drive.google.com/drive/folders/1d5vk9nrse4lJ55wb5zsW2wgodkwWb-V2?usp=sharing) and Initialize\n",
    "\n",
    "- Run all code and test examples by replacing chars\n",
    "- Please note I set topk=1 and tempature=1.0 for reproduce, play with different inference params when you run it.\n",
    "- 重要：[模型文件](https://drive.google.com/drive/folders/1d5vk9nrse4lJ55wb5zsW2wgodkwWb-V2?usp=sharing)存在Google Drive，推荐用Google账号打开，点击`Add to shortcut`，之后在你Drive的主页面`shared with me`看到目录后选择`add shortcut to Drive`，这样可以mount后本地可以操作文件，但要注意路径一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R1I78Xu--Jx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hCg7PwbO-4n5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install keras-transformer &> /dev/null\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "from keras_transformer import get_model, decode, get_custom_objects\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6SM55DRH-H-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOXsqTQWtThU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive if you have your copies of model/configs\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dujcdkTu_C6h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copy https://drive.google.com/drive/folders/1d5vk9nrse4lJ55wb5zsW2wgodkwWb-V2 and match your local dir here\n",
    "MODEL_DIR = 'drive/MyDrive/ML/Models/szhu_public_062021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq-x1MtE-UUY",
    "outputId": "03b0d07a-4440-4901-c469-6197e8a7c4da",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couplet_model_config.pickle  couplet_vocab.pickle      poem_model.h5\n",
      "couplet_model.h5\t     poem_model_config.pickle  poem_vocab.pickle\n"
     ]
    }
   ],
   "source": [
    "# 如出错，请拷贝最开始介绍的那个Google Drive的所有文件，并mount到colab\n",
    "!ls {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uze7aFdx_Kji",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'couplet_model_config.pickle'), 'rb') as handle:\n",
    "  couplet_model_config = pickle.load(handle)\n",
    "with open(os.path.join(MODEL_DIR, 'couplet_vocab.pickle'), 'rb') as handle:\n",
    "  couplet_vocab_dict = pickle.load(handle)\n",
    "with open(os.path.join(MODEL_DIR, 'poem_model_config.pickle'), 'rb') as handle:\n",
    "  poem_model_config = pickle.load(handle)\n",
    "with open(os.path.join(MODEL_DIR, 'poem_vocab.pickle'), 'rb') as handle:\n",
    "  poem_vocab_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-dkvK17OEX78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rev_couplet_vocab_dict = {v: k for k, v in couplet_vocab_dict.items()}\n",
    "rev_poem_vocab_dict = {v: k for k, v in poem_vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dMgyN03D_njJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert 9133 == len(couplet_vocab_dict)\n",
    "assert 11289 == len(poem_vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPNN8DGa_3Ro",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize models and sup methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-3EqiHb9_42B",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "couplet_model = get_model(\n",
    "    embed_weights=np.random.random((len(couplet_vocab_dict),\n",
    "                                    couplet_model_config['embed_dim'])),\n",
    "    **couplet_model_config)\n",
    "couplet_model.load_weights(os.path.join(MODEL_DIR, 'couplet_model.h5'))\n",
    "\n",
    "\n",
    "poem_model = get_model(\n",
    "    embed_weights=np.random.random((len(poem_vocab_dict),\n",
    "                                    poem_model_config['embed_dim'])),\n",
    "    **poem_model_config)\n",
    "poem_model.load_weights(os.path.join(MODEL_DIR, 'poem_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hrRPle-D89G",
    "outputId": "0f3273a1-bcb4-432a-9666-5f2646e69acd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: 秋思\n",
      "正文: 秋风吹雨过，秋色满江城。一叶无人到，千山有客情。\n",
      "上: 欢天喜地度佳节\n",
      "下: 举国迎春贺新年\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN_ID = poem_vocab_dict['<START>']\n",
    "END_TOKEN_ID = poem_vocab_dict['<END>']\n",
    "PAD_TOKEN_ID = poem_vocab_dict['<PAD>']\n",
    "\n",
    "COUPLET_MAX_SEQ_LEN = 34\n",
    "POEM_MAX_INPUT_SEQ = 14\n",
    "POEM_MAX_OUTPUT_SEQ = 66\n",
    "\n",
    "def couplet_inference(pre_couplet, top_k=1, temperature=1.0):\n",
    "  out = \"上: \" + pre_couplet + \"\\n\"\n",
    "  in_vector = [START_TOKEN_ID]\n",
    "  for c in pre_couplet:\n",
    "    in_vector.append(couplet_vocab_dict[c])\n",
    "  in_vector.append(END_TOKEN_ID)\n",
    "  decoded = decode(\n",
    "      couplet_model,\n",
    "      [in_vector],\n",
    "      start_token=couplet_vocab_dict['<START>'],\n",
    "      end_token=couplet_vocab_dict['<END>'],\n",
    "      pad_token=couplet_vocab_dict['<PAD>'],\n",
    "      max_len=COUPLET_MAX_SEQ_LEN,\n",
    "      top_k=top_k,\n",
    "      temperature=temperature,\n",
    "  )\n",
    "  for i in range(len(decoded)):\n",
    "    out += '下: ' + ''.join(map(lambda x: rev_couplet_vocab_dict[x],\n",
    "                       decoded[i][1:-1]))\n",
    "  print(out)\n",
    "\n",
    "def poem_encode(raw_text, is_decode_input, is_decode_output):\n",
    "  assert not (is_decode_input and is_decode_output)\n",
    "  output = []\n",
    "  if not is_decode_output:\n",
    "    output.append(START_TOKEN_ID)\n",
    "  for c in raw_text:\n",
    "    output.append(poem_vocab_dict[c])\n",
    "  output.append(END_TOKEN_ID)\n",
    "  # padding\n",
    "  total_size = POEM_MAX_OUTPUT_SEQ if is_decode_input or is_decode_output else POEM_MAX_INPUT_SEQ\n",
    "  for i in range(total_size - len(output)):\n",
    "    output.append(PAD_TOKEN_ID)\n",
    "  return output\n",
    "\n",
    "def poem_decode(token_ids):\n",
    "  output = \"\"\n",
    "  for token_id in token_ids:\n",
    "    if token_id > 2:\n",
    "      output += rev_poem_vocab_dict[token_id]\n",
    "    elif token_id == 0:\n",
    "      break\n",
    "  return output\n",
    "\n",
    "def poem_inference(title, top_k=1, temperature=1.0):\n",
    "  out = \"标题: \" + title + \"\\n\"\n",
    "  decoded = decode(\n",
    "      poem_model,\n",
    "      poem_encode(title, False, False),\n",
    "      start_token=START_TOKEN_ID,\n",
    "      end_token=END_TOKEN_ID,\n",
    "      pad_token=PAD_TOKEN_ID,\n",
    "      max_len=POEM_MAX_OUTPUT_SEQ,\n",
    "      top_k=top_k,\n",
    "      temperature=temperature,\n",
    "  )\n",
    "  out += \"正文: \" + poem_decode(decoded)\n",
    "  print(out)\n",
    "\n",
    "poem_inference('秋思')\n",
    "couplet_inference('欢天喜地度佳节')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIrhA85CHWcI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKkbnDPHGbGo",
    "outputId": "8dd311cc-49ea-4622-eb10-6b3369d194d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上: 欢天喜地度佳节\n",
      "下: 举国迎春贺新年\n",
      "上: 不待鸣钟已汗颜，重来试手竟何艰\n",
      "下: 只缘沧海常风雨，再去翻身只等闲\n",
      "上: 当年欲跃龙门去，今日真披马革还\n",
      "下: 此际重逢凤阙来，明朝再赋凤凰鸣\n",
      "上: 载歌在谷\n",
      "下: 如醉如痴\n"
     ]
    }
   ],
   "source": [
    "for pre in ['欢天喜地度佳节', '不待鸣钟已汗颜，重来试手竟何艰',\n",
    "            '当年欲跃龙门去，今日真披马革还', '载歌在谷']:\n",
    "  couplet_inference(pre, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zx-xnGr_E--u",
    "outputId": "76c8a55a-639a-4f18-b186-cfbeab2cfef2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: 秋思\n",
      "正文: 秋风吹雨过，秋色满江城。一叶无人到，千山有客情。\n",
      "标题: 百度\n",
      "正文: 百尺孤城上，千金万里中。山川无限水，水石有余风。\n",
      "标题: 湾区春日之谜\n",
      "正文: 春风吹雨不成秋，春色如何一日休。不是春光无处着，只应春色是人愁。\n",
      "标题: 自由而无用之灵魂\n",
      "正文: 我生不知，不识不知。我之不知，我之不知。我亦不知，不如不知。我亦不知，不知何爲。\n"
     ]
    }
   ],
   "source": [
    "for t in ['秋思', '百度', '湾区春日之谜', '自由而无用之灵魂']:\n",
    "  poem_inference(t, top_k=1, temperature=1.0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ipB2xHkn-asg",
    "4R1I78Xu--Jx"
   ],
   "include_colab_link": true,
   "name": "RC-01: AI Writing Demo 06/2021",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}